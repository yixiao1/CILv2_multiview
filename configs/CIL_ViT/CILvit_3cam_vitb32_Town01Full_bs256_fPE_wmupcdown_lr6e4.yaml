#### Model Related Parameters ####
#### Training Related Parameters ####
MAGICAL_SEED: 1314520
DATA_PARALLEL: True
BATCH_SIZE: 256
NUM_WORKER: 4
NUMBER_EPOCH: 60  # Number of epochs to train
TARGETS: ['steer', 'acceleration']  # the targets that the network should estimate
ACCELERATION_AS_ACTION: True
OTHER_INPUTS: ['speed', 'direction'] # extra input to the neural network
# These datasets have 529525 images in total
TRAIN_DATASET_NAME: ['Roach_carla0913_fps10/Roach_carla0913_fps10_dense_normalcamera_LBC_3cam', 'Roach_carla0913_fps10/Roach_carla0913_fps10_dense_normalcamera_NoCrash_3cam'] # Folders of the used training datasets. Should be inside DATASET_PATH folder
VALID_DATASET_NAME: ['Roach_carla0913_fps10/Roach_LBCRoutes_3cam_valid'] # Folders of the used offline evaluation datasets. Should be inside DATASET_PATH folder
ENCODER_INPUT_FRAMES_NUM: 1
ENCODER_STEP_INTERVAL: 1
ENCODER_OUTPUT_STEP_DELAY: 0
DECODER_OUTPUT_FRAMES_NUM: 1
IMG_NORMALIZATION:     # ImageNet normalization
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
IMAGE_SHAPE: [3, 224, 224]  # Input image shape; we have lowered this for vanilla ViT deployment (300 => 224)
DATA_USED: ['rgb_left', 'rgb_central', 'rgb_right']  # Multi-view cameras, it needs to be set in this order
DATA_COMMAND_ONE_HOT: True   # encode high-level command to one-hot
DATA_COMMAND_CLASS_NUM: 4    # Number of commands: 4 for single-lane towns, 6 for multi-lane towns (lane change)
# Data normalization: might be changed depending on datasets
DATA_NORMALIZATION:
  steer: [-1.0, 1.0]  # [left, right]
  acceleration: [-1.0, 1.0]  # [full brake, full throttle]
  speed: [-1.0, 11.0]     # in m/s; [reverse, max speed]

# Loss Parameters #
LOSS: 'Action_nospeed_L1'  # no speed L1 loss
LOSS_WEIGHT:
  actions:
    steer: 0.50
    acceleration: 0.50

# Optimizer Parameters #
LEARNING_RATE: 0.0006
LEARNING_RATE_MINIMUM: 0.00001
LEARNING_RATE_SCHEDULE: 'warmup_cooldown'  # linear warmup, cosine cooldown
LEARNING_RATE_POLICY:
  warmup: 0.01  # 1% of the total epochs

#### Validation Related Parameters ####
EVAL_SAVE_LAST_ATT_MAPS: True
EVAL_BATCH_SIZE: 30
EVAL_SAVE_EPOCHES: [5, 15, 30, 40, 50, 60]
EARLY_STOPPING: False
EVAL_IMAGE_WRITING_NUMBER: 100
EVAL_DRAW_OFFLINE_RESULTS_GRAPHS: ['MAE_steer', 'MAE_acceleration', 'MAE']

### Network Parameters ####
# Encoder part#
IMAGENET_PRE_TRAINED: True
CMD_SPD_TOKENS: False  # Setup [CMD] and [SPD] tokens instead of addition
LEARNABLE_POS_EMBED: False
PRETRAINED_ACC_STR_TOKENS: False  # Initialize [ACC] and [STR] tokens as clones of the (pretrained) [CLS] token
FREEZE_CLS_TOKEN: False  # freeze the [CLS] token
REMOVE_CLS_TOKEN: False  # Remove the [CLS] token from the sequence

MODEL_TYPE: 'CIL_ViT'
# Based on the MODEL_TYPE, we specify the structure
MODEL_CONFIGURATION:
  encoder_embedding:
    perception:
      vit:
        name: 'vit_b_32'
        layer_id: 4  # Remove

  command:
    fc:
      neurons: [512]
      dropouts: [0.0]

  speed:
    fc:
      neurons: [512]
      dropouts: [0.0]